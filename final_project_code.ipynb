{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cis700_project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "y3xhsbAP_T9o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CIS 700 Final Project Colab file\n",
        "Authors: Dhruv Desai, Rahul Shekhar"
      ]
    },
    {
      "metadata": {
        "id": "LQkC7lBEc06F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dhruvd25/cis700_project.git\n",
        "!mv cis700_project/helper.py .\n",
        "!mv cis700_project/celebloader.py .\n",
        "!mv cis700_project/Generator6 ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBqPAse0JtxY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import drive\n",
        "from scipy.io import loadmat\n",
        "from scipy.io import savemat\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from importlib.machinery import SourceFileLoader\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from helper import Logger\n",
        "from celebloader import celebrity\n",
        "# CUDA for PyTorch\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7oiaJ44FDxmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZoJmRjNmF8HL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8g8WY6AG_Vf-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r ./logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c842voLNGJdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e3-OgMmDzX0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mat_file_loc = '/content/cis700_project/wiki_edit.mat'\n",
        "root_dir_loc = '/content/cis700_project/wiki_crop'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X5W4mcSz-CQ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sampled images from Dataset"
      ]
    },
    {
      "metadata": {
        "id": "bN-uj5664q8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_size = 64\n",
        "input_transforms = transforms.Compose([\n",
        "            transforms.Resize((input_size, input_size)),\n",
        "            transforms.ToTensor()])\n",
        "\n",
        "dataset = celebrity(landmarks_frame = mat_file_loc\n",
        "                                ,root_dir=root_dir_loc,\n",
        "                                transform=input_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size = 8,\n",
        "                                           shuffle = True)\n",
        "train_iter = iter(train_loader)\n",
        "images, labels = train_iter.next()\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "plt.axis('off')\n",
        "plt.title(labels.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nivFwxK25z0u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Non-Deep Learning benchmark for classification (Logistic Regression model)"
      ]
    },
    {
      "metadata": {
        "id": "S4bG-BCMtCMG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_size = 64\n",
        "num_classes = 2\n",
        "num_epochs = 5\n",
        "learning_rate = 0.001\n",
        "  \n",
        "class LogisticRegression(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.linear = torch.nn.Linear(64*64*3,3)\n",
        "  def forward(self,x):\n",
        "    x = x.view(x.size(0), -1)\n",
        "    out = self.linear(x)\n",
        "    return out\n",
        "\n",
        "model = LogisticRegression().to(device)\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "logger = Logger('./logs/'+str(1))\n",
        "\n",
        "steps = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i < 286:\n",
        "          # Load images as Variable\n",
        "          images = images.view(-1, 64*64*3).requires_grad_().to(device)\n",
        "          labels = labels.to(device)\n",
        "          # Clear gradients w.r.t. parameters\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Forward pass to get output/logits\n",
        "          outputs = model(images)\n",
        "\n",
        "          # Calculate Loss: softmax --> cross entropy loss\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Getting gradients w.r.t. parameters\n",
        "          loss.backward()\n",
        "\n",
        "          # Updating parameters\n",
        "          optimizer.step()\n",
        "\n",
        "          _, argmax = torch.max(outputs, 1)\n",
        "          accuracy = (labels == argmax.squeeze()).float().mean()\n",
        "          if steps % 200 == 0:\n",
        "            print(\"Loss:\",loss.item(),'accuracy', accuracy.item())\n",
        "          # 1. Log scalar values (scalar summary)\n",
        "          info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
        "          for tag, value in info.items():\n",
        "              logger.scalar_summary(tag, value, steps+1)\n",
        "\n",
        "          steps += 1\n",
        "\n",
        "# Calculate Accuracy         \n",
        "correct = 0\n",
        "total = 0\n",
        "# Iterate through test dataset\n",
        "for i,(images, labels) in enumerate(train_loader):\n",
        "    if i>286:\n",
        "      # Load images to a Torch Variable\n",
        "      images = images.view(-1, 64*64*3).requires_grad_().to(device)\n",
        "\n",
        "      # Forward pass only to get logits/output\n",
        "      outputs = model(images).to(device)\n",
        "\n",
        "      # Get predictions from the maximum value\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "      # Total number of labels\n",
        "      total += labels.size(0)\n",
        "\n",
        "      # Total correct predictions\n",
        "      correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "\n",
        "# Print Loss\n",
        "print(' Loss: {}. Accuracy: {}'.format( loss.item(), accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-rZ5x5X59xl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Deep Learning Benchmark for classification (CNN)"
      ]
    },
    {
      "metadata": {
        "id": "9j-lnB9V59Z8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()\n",
        "    \n",
        "    self.layer1 = nn.Sequential(\n",
        "                  nn.Conv2d(3, 16, 3, padding = 1),\n",
        "                  nn.BatchNorm2d(16),\n",
        "                  nn.ReLU(),\n",
        "                  nn.MaxPool2d(2,2))\n",
        "    self.layer2 = nn.Sequential(\n",
        "                  nn.Conv2d(16, 32, 3, padding = 1),\n",
        "                  nn.BatchNorm2d(32),\n",
        "                  nn.ReLU(),\n",
        "                  nn.MaxPool2d(2,2))\n",
        "    self.layer3 = nn.Sequential(\n",
        "                  nn.Conv2d(32, 64, 3, padding = 1),\n",
        "                  nn.BatchNorm2d(64),\n",
        "                  nn.ReLU(),\n",
        "                  nn.MaxPool2d(2,2))\n",
        "    self.layer4 = nn.Sequential(\n",
        "                  nn.Conv2d(64, 128, 3, padding = 1),\n",
        "                  nn.BatchNorm2d(128),\n",
        "                  nn.ReLU(),\n",
        "                  nn.MaxPool2d(2,2))    \n",
        "    \n",
        "    self.fc1 = nn.Linear(2048,256)\n",
        "    self.fc2 = nn.Linear(256,2)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    \n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    \n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.dropout(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "    \n",
        "    return self.softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IyPN9kkx62rl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 4\n",
        "learning_rate = 0.0001\n",
        "\n",
        "model = CNN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "logger = Logger('./logs/'+ str(2))\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "steps = 0\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i <= 286:\n",
        "          # Move tensors to the configured device\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          _, argmax = torch.max(outputs, 1)\n",
        "          accuracy = (labels == argmax.squeeze()).float().mean()\n",
        "          if (i+1) % 200 == 0:\n",
        "              print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "          # 1. Log scalar values (scalar summary)\n",
        "          info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
        "          for tag, value in info.items():\n",
        "              logger.scalar_summary(tag, value, steps+1)\n",
        "          steps += 1\n",
        "print(\"Training accuracy:({:.0f}%)\".format(100. * accuracy.item()))\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for i,(images, labels) in enumerate(train_loader):\n",
        "        if i >286:      \n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          output = model(images)\n",
        "          # sum up batch loss\n",
        "          test_loss += F.nll_loss(output, labels, reduction='sum').item() \n",
        "          # get the index of the max log-probability\n",
        "          pred = output.argmax(dim=1, keepdim=True) \n",
        "          correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "          _, argmax = torch.max(output, 1)\n",
        "          accuracy = (labels == argmax.squeeze()).float().mean()\n",
        "test_loss /= 146 \n",
        "print('\\nTest set:Accuracy: {}/{} ({:.0f}%)\\n'\n",
        "      .format(correct,(146*32),100. * correct / (146*32) ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ibnk5CCT_Ew-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Advanced Deep Learning Architecture \n",
        "Conditional DCGAN (cGAN)"
      ]
    },
    {
      "metadata": {
        "id": "BeRs8_V7cmhf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(generator, self).__init__()\n",
        "    f = 512\n",
        "    self.main = nn.Sequential(\n",
        "      nn.ConvTranspose2d(258, f, 4, \n",
        "                         stride = 1, padding = 0 ,bias=False),  #4, 512\n",
        "      nn.BatchNorm2d(f),\n",
        "      nn.ReLU(True),\n",
        "      nn.ConvTranspose2d(f, f//4, 4, \n",
        "                         stride = 2, padding = 1,bias=False), # 8, 128\n",
        "      nn.BatchNorm2d(f//4), \n",
        "      nn.ReLU(True),\n",
        "      nn.ConvTranspose2d(f//4, f//16, 4, \n",
        "                         stride = 2, padding = 1,bias=False), #16, 32\n",
        "      nn.BatchNorm2d(f//16),\n",
        "      nn.ReLU(True),\n",
        "      nn.ConvTranspose2d(f//16, f//64, 4, \n",
        "                         stride = 2, padding = 1,bias=False), #32, 8\n",
        "      nn.BatchNorm2d(f//64), \n",
        "      nn.ReLU(True),\n",
        "      nn.ConvTranspose2d(f//64, 3, 4, \n",
        "                         stride = 2, padding = 1,bias=False), #64,  1\n",
        "      nn.Tanh())  \n",
        "  def forward(self, x):\n",
        "    out = self.main(x)\n",
        "    return out\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(discriminator, self).__init__()\n",
        "    d = 8\n",
        "    self.conv1 = nn.Conv2d(3, d, 4, stride = 2, padding = 1,bias=False)\n",
        "    \n",
        "    self.main = nn.Sequential(\n",
        "      nn.Conv2d(d + 2, d*2, 4, stride = 2, padding = 1,bias=False), # 16\n",
        "      nn.BatchNorm2d(d*2),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      nn.Conv2d(d*2, d*4, 4, stride = 2, padding = 1,bias=False), # 8\n",
        "      nn.BatchNorm2d(d*4),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      nn.Conv2d(d*4, d*8, 4, stride = 2, padding = 1,bias=False), # 4\n",
        "      nn.LeakyReLU(0.2),\n",
        "      nn.BatchNorm2d(d*8),\n",
        "      nn.Conv2d(d*8, 1, 4, stride = 1, padding = 0,bias=False), # 1\n",
        "      nn.Sigmoid())\n",
        "  def forward(self, x, y):\n",
        "    x_1 = self.conv1(x)\n",
        "    x_c = torch.cat((x_1, y), dim = 1)\n",
        "    out = self.main(x_c)\n",
        "    return out\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ttf6BEgjAFc7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GAN parameters"
      ]
    },
    {
      "metadata": {
        "id": "RzNlDX8jykFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_size = 64\n",
        "input_transforms = transforms.Compose([\n",
        "            transforms.Resize((input_size, input_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])\n",
        "dataset = celebrity(landmarks_frame = mat_file_loc\n",
        "                                ,root_dir=root_dir_loc,\n",
        "                                transform=input_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size = 64,\n",
        "                                           shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbqpUJg4bsen",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 2\n",
        "\n",
        "G = generator().to(device)\n",
        "D = discriminator().to(device)\n",
        "\n",
        "G.apply(weights_init)\n",
        "D.apply(weights_init)\n",
        "\n",
        "num_epochs, D_step, G_step, step = 25, 0, 0, 0\n",
        "logger = Logger('./logs/'+ str(3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OjUn5v4IoGo3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Working model params\n",
        "optimizer_G = torch.optim.Adam(G.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(D.parameters(), lr=0.0005, betas = (0.5, 0.999))\n",
        "criterion = nn.BCELoss()\n",
        "real_label, fake_label = 0.90, 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7XoPxPqALIA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training Loop for GAN"
      ]
    },
    {
      "metadata": {
        "id": "HYwlZ0_KBk8M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir GAN_Training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QS6_ygL4ZV3i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  print(epoch)\n",
        "  for images, labels in train_loader:\n",
        "    \n",
        "    images = images.to(device)\n",
        "    sz = len(images)\n",
        "        \n",
        "    fake_D = (fake_label + torch.rand(sz) * 0.1).to(device)  \n",
        "    real_D = (real_label + torch.rand(sz) * 0.1).to(device) \n",
        "    \n",
        "    fake_G = torch.zeros(sz).to(device)  \n",
        "    real_G = torch.ones(sz).to(device)\n",
        "    \n",
        "    \n",
        "    #images += (torch.randn(images.size()) * 0.1).to(device)\n",
        "    #(torch.randn(G_noise_discriminator.size()) * 0.1).to(device)\n",
        "    \n",
        "    \n",
        "    # Discriminator (REAL)\n",
        "    #Create Discriminator concatenated \n",
        "    d_condition = torch.zeros(sz, NUM_CLASSES, 32, 32).to(device)\n",
        "    idx = torch.arange(sz).to(device)\n",
        "    d_condition[idx, labels] = 1\n",
        "    \n",
        "    \n",
        "    D.zero_grad()\n",
        "    D_real_output = D(images, d_condition).squeeze()\n",
        "    \n",
        "    \n",
        "    # TO MODIFY (USING ACTUAL LABELS)\n",
        "    z = torch.randn(sz, 256, 1, 1, device=device)\n",
        "    y_c = (torch.rand(sz, 1) * NUM_CLASSES).type(torch.LongTensor).to(device)\n",
        "    y_label = torch.zeros(sz, NUM_CLASSES).to(device)\n",
        "    y_label.scatter_(1, y_c.view(sz, 1), 1)\n",
        "    y_label = y_label.reshape(sz, NUM_CLASSES, 1, 1)\n",
        "    final_z_vec_D = torch.cat((z, y_label), dim = 1).to(device)\n",
        "    \n",
        "    d_condition = torch.zeros(sz, NUM_CLASSES, 32, 32).to(device)\n",
        "    idx = torch.arange(sz).to(device)\n",
        "    d_condition[idx, y_c.squeeze()] = 1\n",
        "      \n",
        "    G_noise_discriminator = G(final_z_vec_D).to(device)\n",
        "    \n",
        "    D_fake_output = D(G_noise_discriminator, d_condition).squeeze()\n",
        "    \n",
        "    D_real_loss = criterion(D_real_output, real_D)\n",
        "    D_fake_loss = criterion(D_fake_output, fake_D)\n",
        "\n",
        "    \n",
        "    D_loss = (D_real_loss + D_fake_loss)/2\n",
        "    D_loss.backward()\n",
        "    optimizer_D.step()\n",
        "    \n",
        "\n",
        "    # GENERATOR\n",
        "    G.zero_grad() #equal to detaching the Generator\n",
        "    z = torch.randn(sz, 256, 1, 1, device=device).to(device)\n",
        "    \n",
        "    \n",
        "    #adding condition to noise vector\n",
        "    y_c = (torch.rand(sz, 1) * NUM_CLASSES).type(torch.LongTensor).to(device)\n",
        "    y_label = torch.zeros(sz, NUM_CLASSES).to(device)\n",
        "    y_label.scatter_(1, y_c.view(sz, 1), 1)\n",
        "    y_label = y_label.reshape(sz, NUM_CLASSES, 1, 1)\n",
        "      \n",
        "    final_z_vec_G = torch.cat((z, y_label), dim = 1).to(device)\n",
        "\n",
        "    d_condition = torch.zeros(sz, NUM_CLASSES, 32, 32).to(device)\n",
        "    idx = torch.arange(sz).to(device)\n",
        "    d_condition[idx, y_c.squeeze()] = 1\n",
        "    \n",
        "    \n",
        "    G_noise_generator = G(final_z_vec_G).to(device)\n",
        "    D_generator_output = D(G_noise_generator, d_condition).squeeze()\n",
        "    G_loss = criterion(D_generator_output, real_G)\n",
        "    G_loss.backward()\n",
        "    optimizer_G.step()\n",
        "    \n",
        "    \n",
        "    info = {'Total D Loss': D_loss.item(), 'D Real Loss': D_real_loss.item(), \n",
        "            'D Fake Loss': D_fake_loss.item(), 'G Loss': G_loss.item()}\n",
        "    for tag, value in info.items():\n",
        "      logger.scalar_summary(tag, value, step + 1)\n",
        "    \n",
        "    if step % 500 == 0:\n",
        "      print('saved')\n",
        "      torchvision.utils.save_image(G_noise_generator.data, 'GAN_Training/' + \n",
        "                                   str(step)+ '.png', normalize=True)\n",
        "      torchvision.utils.save_image(images.data, 'GAN_Training/Original' + \n",
        "                             str(step)+ '.png', normalize=True)\n",
        "      \n",
        "    step += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s42K8PTVHksF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r GAN_Training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MguaJsEaUh1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving and downloading model weights\n",
        "from google.colab import files\n",
        "torch.save(G.state_dict(), \"Generator\")\n",
        "torch.save(D.state_dict(), \"Disc\")\n",
        "files.download('Generator')\n",
        "files.download('Disc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e4-JgA4JuBJt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load trained Generator model\n",
        "model = generator().to(device)\n",
        "model.load_state_dict(torch.load('Generator6'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N9CXqxls-9WP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating synthetic dataset using trained Generator"
      ]
    },
    {
      "metadata": {
        "id": "igHFDxepqXed",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "synthetic_data = []\n",
        "NUM_CLASSES = 2\n",
        "#Creating synthetic dataset\n",
        "for i in range(100000):\n",
        "  sz = 1\n",
        "  z = torch.randn(sz, 256, 1, 1, device=device).to(device)\n",
        "  #adding condition to noise vector\n",
        "  y_c = (torch.rand(sz, 1) * NUM_CLASSES).type(torch.LongTensor).to(device)\n",
        "  y_label = torch.zeros(sz, NUM_CLASSES).to(device)\n",
        "  y_label.scatter_(1, y_c.view(sz, 1), 1)\n",
        "  y_label = y_label.reshape(sz, NUM_CLASSES, 1, 1)\n",
        "  final_z_vec_G = torch.cat((z, y_label), dim = 1).to(device)\n",
        "  \n",
        "  G_noise_generator = model(final_z_vec_G).to(device)\n",
        "  \n",
        "  synthetic_data.append([G_noise_generator.data, z])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9OCsl9Mo1f8x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader_E = torch.utils.data.DataLoader(synthetic_data, batch_size = 64,\n",
        "                                           shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iqwiAMDu_mGr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Encoder Architecture"
      ]
    },
    {
      "metadata": {
        "id": "QHCDwdmgYUbP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(encoder, self).__init__()\n",
        "    self.encode = nn.Sequential(\n",
        "      nn.Conv2d(3, 32, 5, stride = 2), \n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.ReLU(),\n",
        "      #nn.MaxPool2d(2, stride = 2), \n",
        "      nn.Conv2d(32, 64, 5, stride = 2), \n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      #nn.MaxPool2d(2, stride = 2),\n",
        "      nn.Conv2d(64, 128, 5, stride = 2),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      #nn.MaxPool2d(2, stride = 2), \n",
        "      nn.Conv2d(128, 256, 5, stride = 2),\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ReLU(),\n",
        "      #nn.MaxPool2d(2, stride = 2) # 256 * 1 * 1 \n",
        "    )\n",
        "    \n",
        "    self.fc1 = nn.Linear(256, 4096)\n",
        "    self.bc1 = nn.BatchNorm1d(4096)\n",
        "    self.fc2 = nn.Linear(4096, 256)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.encode(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = F.relu(self.bc1(self.fc1(out)))\n",
        "    out = self.fc2(out)\n",
        "    \n",
        "    return out.view(out.size(0), 256, 1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-lM8Mxp9AAwU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Encoder training "
      ]
    },
    {
      "metadata": {
        "id": "IyX-8ftnBw5M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir Encoder_Training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YtZVm9Yh_Sey",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "E = encoder().to(device)\n",
        "# E.apply(weights_init)\n",
        "criterion_E = nn.MSELoss()\n",
        "optimizer_E = torch.optim.Adam(E.parameters(), \n",
        "                               lr = 0.0002, betas = (0.5, 0.999))\n",
        "\n",
        "num_epochs, step = 25, 0\n",
        "\n",
        "logger = Logger('./logs/'+ str(4))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print('epoch: ' + str(epoch))\n",
        "  for i, (images, labels) in enumerate(train_loader_E):\n",
        "    images = images.squeeze().to(device)\n",
        "    output = E(images)\n",
        "    labels = labels.reshape(output.shape)\n",
        "          \n",
        "    loss = criterion_E(output, labels)\n",
        "    \n",
        "    optimizer_E.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_E.step()\n",
        "\n",
        "    if step % 200 == 0:\n",
        "      print(loss.item())\n",
        "    info = {'loss': loss.item()}\n",
        "    for tag, value in info.items():\n",
        "      logger.scalar_summary(tag, value, step + 1)\n",
        "    torchvision.utils.save_image(images.data, 'Encoder_Training/' + \n",
        "                                 str(i)+ '.png', normalize=True)\n",
        "    \n",
        "    step += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t3rUSkiIB23N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r Encoder_Training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mu04OspxASfR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Comparing outputs from trained GAN with and without Encoder"
      ]
    },
    {
      "metadata": {
        "id": "-HgfSS6SB7jw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir Latent_Training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WlcHuVPoAopi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "G_final = generator().to(device)\n",
        "G_final.load_state_dict(torch.load(\"Generator6\"))\n",
        "NUM_CLASSES = 2\n",
        "for i, (images, labels) in enumerate(train_loader):\n",
        "  sz = len(images)\n",
        "  images = images.to(device)\n",
        "  G_input = E(images)\n",
        "  y_c = (torch.rand(sz, 1) * NUM_CLASSES).type(torch.LongTensor).to(device)\n",
        "  y_label = torch.zeros(sz, NUM_CLASSES).to(device)\n",
        "  y_label.scatter_(1, y_c.view(sz, 1), 1)\n",
        "  y_label = y_label.reshape(sz, NUM_CLASSES, 1, 1)\n",
        "  \n",
        "  final_E_vec_G = torch.cat((G_input, y_label), dim = 1).to(device)\n",
        "  \n",
        "   \n",
        "  #z = torch.randn(sz, 256, 1, 1, device=device).to(device)\n",
        "  #final_z_vec_G = torch.cat((z, y_label), dim = 1).to(device)\n",
        "\n",
        "  G_E_generator = G_final(final_E_vec_G).to(device)\n",
        "  G_Z_generator = G_final(final_z_vec_G).to(device)\n",
        "  torchvision.utils.save_image(G_E_generator.data, 'Latent_Training/E' \n",
        "                               + str(i)+ '.png', normalize=True)\n",
        "  torchvision.utils.save_image(G_Z_generator.data, 'Latent_Training/N' \n",
        "                               + str(i)+ '.png', normalize=True)\n",
        "  torchvision.utils.save_image(images.data, 'Latent_Training/Original' \n",
        "                               + str(i)+ '.png', normalize=True)\n",
        "  \n",
        "  if i > 10:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bCy8lBsVYZQ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r Latent_Training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "paYgLK7a_8Yn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Code to see output for different labels but same noise vector\n"
      ]
    },
    {
      "metadata": {
        "id": "WN4qbcTnCA_G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir Age"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2F9wMHP0zHh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "G_final = generator().to(device)\n",
        "G_final.load_state_dict(torch.load(\"Generator6\"))\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "for i in range(5):\n",
        "  sz = 64\n",
        "  z = torch.randn(sz, 256, 1, 1, device=device).to(device)\n",
        "  \n",
        "  #y_c = (torch.rand(sz, 1) * NUM_CLASSES).type(torch.LongTensor).to(device)\n",
        "  \n",
        "  y_c0 = torch.tensor([[0] * 64]).type(torch.LongTensor).to(device)\n",
        "  y_c1 = torch.tensor([[1] * 64]).type(torch.LongTensor).to(device)\n",
        "  \n",
        "  y_label0 = torch.zeros(sz, NUM_CLASSES).to(device)\n",
        "  y_label0.scatter_(1, y_c0.view(sz, 1), 1)\n",
        "  y_label0 = y_label0.reshape(sz, NUM_CLASSES, 1, 1)\n",
        "  y_0_cat = torch.cat((z, y_label0), dim = 1).to(device)\n",
        "  \n",
        "\n",
        "  y_label1 = torch.zeros(sz, NUM_CLASSES).to(device)\n",
        "  y_label1.scatter_(1, y_c1.view(sz, 1), 1)\n",
        "  y_label1 = y_label1.reshape(sz, NUM_CLASSES, 1, 1)\n",
        "  y_1_cat = torch.cat((z, y_label1), dim = 1).to(device)\n",
        "  \n",
        "  \n",
        "  G_E_generator0 = G_final(y_0_cat).to(device)\n",
        "  G_E_generator1 = G_final(y_1_cat).to(device)\n",
        "  \n",
        "  torchvision.utils.save_image(G_E_generator0.data, 'Age/' \n",
        "                               + str(i)+'Young'+ '.png', normalize=True)\n",
        "  torchvision.utils.save_image(G_E_generator1.data, 'Age/' \n",
        "                               + str(i)+ 'Old'+'.png', normalize=True)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-eZyS51d4gA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r Age"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}